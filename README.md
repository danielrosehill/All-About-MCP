# All About MCP: A Fully Agent-Authored Coursebook

*All About MCP* is intended as a personal learning resource and offered, open source, as a model—demonstrating the specific pattern followed for creating long-form report-style documents using AI agents.

I've used this pattern on several occasions to create course-like "textbooks" that I have printed and converted into audiobook format.

---

## Philosophy: On AI-Generated Educational Content

I create this material under the expectation that it may not be entirely accurate. When developing it for my own use, I haven't felt the need to encumber the natural flow of text with disclaimers. But so far I have been generally pleasantly surprised by the accuracy of the information contained.

As retrieval and grounding systems become more mature and reliable, the assumption that everything generated by AI is inherently untrustworthy will (I predict and already see) become untenable.

At a certain point, we humans may be forced to accept, with humility, that AI is "good enough" at synthesising information accurately—and maybe even better at the task than we are.

None of this is to suggest that human authorship is any less valuable than it was at any prior point in time. Merely to suggest that LLMs can be leveraged as highly effective information-synthesising tools for humans wishing to explore a complex subject in depth. And that doing so is a net positive for streamlining self-directed learning.

---

## The Core Mechanism: Chunked Generation and Stitching

The recipe I have used for generating long-form content is stitching-based: LLMs degrade in accuracy as context accumulates. So asking a large language model to write an entire book, or even a swathe of it, in one shot will tend to yield poor results. Even if the model is capable of completing enough tokens to generate large chunks of text in one output, results may be dramatically inferior to when that same model is asked to generate text in shorter bursts.

For that reason, the methodology I have found success with—and share in this template—is approximately this:

### Step 1: Curriculum Development (Human)

The human develops a "curriculum" functioning as an outline of the topics to be covered in the long-form coursebook. This is effectively a table of contents. This is a fun process! The human can map out a personalised curriculum defining precisely what they wish to learn within this (large) topic.

### Step 2: Prompt Chunking (Agent)

A second agent can be used to chunk this into specific text generation prompts. Claude Code (which I'm using to create this) provides a simple and elegant mechanism for doing exactly this: the curriculum chunking agent can chunk up the curriculum and form prompts for the curriculum writing agent, who can then author individual chapters.

### Step 3: Chapter Generation (Agent)

The large language model conducts the work of running the individual generation prompts one by one. In the most efficient architecture, several agents could be delegated to run this task in parallel. For simplicity of orchestration, the easiest implementation is just to have one single agent working through a list to validate completion.

### Step 4: Stitching (Agent)

Finally, a stitching agent is responsible for "stitching" the outputs together into a single readable document.

### Optional Enhancements

- The authoring agent could be instructed to use Mermaid in order to create flowcharts for explanations that benefit from diagrammatic representation.
- Authoring agents can also leverage image generation tooling in order to create engaging images to break up the monotony of pure text.

---

## Text Formatting and Output Creation

My workloads have targeted Markdown as the initial concatenation format for its versatility.

From Markdown, I tend to target PDF.

For best results, an agent is best used for this process. The best mechanism for converting a very lengthy Markdown document into a PDF is difficult to define programmatically (in advance) owing to the inherent variability of the text that the large language model will generate. An agent is highly useful for its ability to think: "Which of the 10 ways I can create a PDF from this will yield the best result?"

### Formatting Requirements

A little bit of instructing is usually necessary in my experience in order to define requirements like that every new chapter begin on a new page. These requirements might seem obvious, but it's frequently necessary to state them rather than hope or expect that they will be inferred.

To make the end document presentable and readable, I usually also ask for:
- A title page
- A table of contents
- Page numbers in the footer
- Other basic formatting elements

Finally, a PDF is stitched together.

---

## Audiobook Conversion

I enjoy consuming long-form content through audio.

The mechanism I've used to date for getting from the large Markdown document to audio is probably inferior to that which others have come up with (it's impossible to keep up with AI!).

### My Current Approach

1. **Text Conversion**: Use an LLM to convert Markdown into TTS-friendly text. The best practice here I've found is to instruct the agent according to the TTS that you're targeting and the prosody that it supports.
2. **Audio Generation**: Pass the text to a TTS model. Like the text generation, this also needs to be chunked and then stitched together.

So essentially the model involves reformatting the delivered text, instructing the LLM to omit non-readable elements (like diagrams). This is again another use case in which LLMs come into their own: simple regex does not, in my experience, get far enough.

---

## Use Cases

I found this to be a brilliant way to get a quick "bring me up to speed" style guide on a subject.

Given that the concatenation is scripted and therefore doesn't impose a direct impediment to context, I don't believe there is an inherent limit as to the length of the ultimate document generated. I've created documents that are hundreds of pages long.

---

## Coherence and Task Retention

One aspect of this task that is challenging is how to maintain coherence throughout the text.

The stitched document should not read like a stitched composite of short outputs. Ensuring fluency and consistency between the chapters is challenging.

### Solutions

**Previous Chapter Context**: One potential solution at the prompting level is to instruct the chapter generation agent to read (only) the previous chapter. By asking it to parse only one previous output, this limits the context, preventing the generation context and the previous context from overwhelming context windows.

**Style Guide**: Paralleling the process used by human authors, a style guide is also an effective mechanism. The agent gets sight of the overall task and the tone of voice to be used in the composition. This can also be used to ensure consistent formatting, ranging from source formatting to even the type of referencing used.

---

## Repository Structure

This repository serves a dual purpose:

1. **Demonstrating the pattern**: Showing how this chunked generation and stitching process works in practice
2. **Generating deliverables**: Creating the actual MCP coursebook for personal reading and listening

The `CLAUDE.md` file contains the specific generation task context for the MCP coursebook. 
